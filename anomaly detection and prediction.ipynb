{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab4c9af-bcd5-4073-8c17-ec9ec37526be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from pandas import json_normalize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- CONFIG ---\n",
    "client = \"https://my-elasticsearch-project-eb24cb.es.eu-west-1.aws.elastic.cloud:443\"\n",
    "API_KEY_1 = \"WDBOaHlwY0JEVV9IeldsV1RhNE46TEpWdkpKcy1JTlNlQ1gzQWJCMEhVdw==\"\n",
    "INDEX_READ = \".ds-metrics-system.process-default-2025.07.02-000001\"\n",
    "INDEX_TARGET = \"anomaly\"\n",
    "\n",
    "# --- CONNECT TO ELASTICSEARCH ---\n",
    "es = Elasticsearch(hosts=[client], api_key=API_KEY_1, verify_certs=True)\n",
    "\n",
    "# --- FETCH DATA ---\n",
    "def fetch_data(size=5000):\n",
    "    query = {\n",
    "        \"size\": size,\n",
    "        \"query\": {\"match_all\": {}},\n",
    "        \"sort\": [{\"@timestamp\": {\"order\": \"desc\"}}],\n",
    "        \"_source\": [\n",
    "            \"@timestamp\", \"host.name\",\n",
    "            \"system.process.cpu.total.value\", \"system.process.memory.size\",\n",
    "            \"process.cpu.pct\", \"event.duration\",\n",
    "            \"process.name\", \"process.memory\", \"host.os.name\", \"process.state\"\n",
    "        ]\n",
    "    }\n",
    "    res = es.search(index=INDEX_READ, body=query)\n",
    "    docs = [hit['_source'] for hit in res['hits']['hits']]\n",
    "    df = pd.DataFrame(docs)\n",
    "    df = json_normalize(df.to_dict(orient='records'))\n",
    "    return df\n",
    "\n",
    "# --- LABEL ANOMALIES BASED ON Z-SCORE + IQR ---\n",
    "def label_anomalies(df, feature_cols, z_thresh=3.0):\n",
    "    df['anomaly_label'] = 0\n",
    "    for col in feature_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(float)\n",
    "            z_scores = np.abs((df[col] - df[col].mean()) / df[col].std())\n",
    "            z_outliers = z_scores > z_thresh\n",
    "\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            iqr_outliers = (df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)\n",
    "\n",
    "            df['anomaly_label'] = df['anomaly_label'] | ((z_outliers | iqr_outliers).astype(int))\n",
    "    return df\n",
    "\n",
    "# --- COMPARE MULTIPLE MODELS ---\n",
    "def compare_models(X, y, df_original, folds=10):\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    models = {\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"SVM\": SVC(kernel='rbf', probability=True, random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier()\n",
    "    }\n",
    "    results = {}\n",
    "    confusion_matrices = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        accs, precs, recalls, f1s = [], [], [], []\n",
    "        all_preds, all_true = [], []\n",
    "\n",
    "        for train_idx, test_idx in skf.split(X, y):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            accs.append(accuracy_score(y_test, y_pred))\n",
    "            precs.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "            recalls.append(recall_score(y_test, y_pred, zero_division=0))\n",
    "            f1s.append(f1_score(y_test, y_pred, zero_division=0))\n",
    "\n",
    "            all_preds.extend(y_pred)\n",
    "            all_true.extend(y_test)\n",
    "\n",
    "        results[name] = {\n",
    "            \"Accuracy\": np.mean(accs),\n",
    "            \"Precision\": np.mean(precs),\n",
    "            \"Recall\": np.mean(recalls),\n",
    "            \"F1 Score\": np.mean(f1s)\n",
    "        }\n",
    "        confusion_matrices[name] = confusion_matrix(all_true, all_preds)\n",
    "\n",
    "    print(\"\\nModel Comparison (Average of {} folds):\".format(folds))\n",
    "    print(\"{:<20} {:>8} {:>10} {:>10} {:>10}\".format(\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"))\n",
    "    for name, metrics in results.items():\n",
    "        print(\"{:<20} {:8.4f} {:10.4f} {:10.4f} {:10.4f}\".format(\n",
    "            name, metrics[\"Accuracy\"], metrics[\"Precision\"], metrics[\"Recall\"], metrics[\"F1 Score\"]\n",
    "        ))\n",
    "        print(\"Confusion Matrix ({}):\\n{}\\n\".format(name, confusion_matrices[name]))\n",
    "\n",
    "    return models['Random Forest'].fit(X, y).predict(X), models['Decision Tree'].fit(X, y).predict(X)\n",
    "\n",
    "# --- PUSH TO ELASTICSEARCH ---\n",
    "def push_to_elasticsearch(df, rf_preds, dt_preds):\n",
    "    actions = []\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            doc = {\n",
    "                '_index': INDEX_TARGET,\n",
    "                '_source': {\n",
    "                    '@timestamp': pd.to_datetime(row['@timestamp']).isoformat() if not pd.isnull(row['@timestamp']) else None,\n",
    "                    'agent_name': str(row.get('host.name', '')),\n",
    "                    'system.process.cpu.total.value': float(row.get('system.process.cpu.total.value', 0)),\n",
    "                    'system.process.memory.size': float(row.get('system.process.memory.size', 0)),\n",
    "                    'process.cpu.pct': float(row.get('process.cpu.pct', 0)),\n",
    "                    'event.duration': float(row.get('event.duration', 0)),\n",
    "                    'process.name': str(row.get('process.name', '')),\n",
    "                    'host.os.name': str(row.get('host.os.name', '')),\n",
    "                    'process.state': str(row.get('process.state', '')),\n",
    "                    'process.memory': str(row.get('process.memory', '')),\n",
    "                    'anomaly_label': int(row.get('anomaly_label', 0)),\n",
    "                    'rf_pred': int(rf_preds[i]),\n",
    "                    'dt_pred': int(dt_preds[i])\n",
    "                }\n",
    "            }\n",
    "            actions.append(doc)\n",
    "        except Exception as e:\n",
    "            print(f\"[SKIPPED] Row {i} failed: {e}\")\n",
    "\n",
    "    if actions:\n",
    "        success, _ = helpers.bulk(es, actions)\n",
    "        print(f\" Indexed {success} documents to '{INDEX_TARGET}'\")\n",
    "    else:\n",
    "        print(\"! No valid documents to push.\")\n",
    "\n",
    "\n",
    "# --- MAIN PIPELINE ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Fetching data...\")\n",
    "    df = fetch_data(size=5000)\n",
    "\n",
    "    features = [\n",
    "        \"system.process.cpu.total.value\",\n",
    "        \"system.process.memory.size\",\n",
    "        \"event.duration\",\n",
    "        \"process.cpu.pct\"\n",
    "    ]\n",
    "    df.dropna(subset=features, inplace=True)\n",
    "\n",
    "    print(\"Creating anomaly labels...\")\n",
    "    df = label_anomalies(df, features, z_thresh=3.0)\n",
    "\n",
    "    print(\"Encoding categorical features...\")\n",
    "    label_encoders = {}\n",
    "    for col in ['host.os.name', 'process.name', 'process.state']:\n",
    "        if col in df.columns:\n",
    "            le = LabelEncoder()\n",
    "            df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "\n",
    "    encoded_features = features + [f'{col}_encoded' for col in label_encoders]\n",
    "    X = df[encoded_features]\n",
    "    y = df['anomaly_label']\n",
    "\n",
    "    print(\"Comparing all 6 model performances...\")\n",
    "    rf_preds, dt_preds = compare_models(X, y, df)\n",
    "\n",
    "    print(\"Pushing RF and DT predictions to Elasticsearch...\")\n",
    "    push_to_elasticsearch(df.reset_index(drop=True), rf_preds, dt_preds)\n",
    "\n",
    "    print(\"\\n[âœ“] Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
